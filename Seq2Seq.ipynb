{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from torch.cuda.amp import autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42069\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos = '|<sos>|'\n",
    "eos = '|<eos>|'\n",
    "pad = '|<pad>|'\n",
    "oov = '|<oov>|'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab(object):\n",
    "    \n",
    "    def __init__(self, VocabList, language):\n",
    "        \n",
    "        self.sos = sos\n",
    "        self.eos = eos\n",
    "        self.pad = pad\n",
    "        self.oov = oov\n",
    "        self.char2idx = {self.sos: 0, self.eos: 1, self.pad: 2, self.oov: 3}\n",
    "        self.idx2char = [self.sos, self.eos, self.pad, self.oov]\n",
    "        self.vocab_count = 4\n",
    "        \n",
    "        self.language = language\n",
    "        self.build_tokenizer()\n",
    "        self.build_vocab(VocabList)\n",
    "        \n",
    "        \n",
    "    def build_tokenizer(self):\n",
    "        if self.language == \"english\":\n",
    "            self.tokenizer = get_tokenizer('spacy', language='en')\n",
    "        elif self.language == \"spanish\":\n",
    "            self.tokenizer = get_tokenizer('spacy', language='es_core_news_lg')   \n",
    "    \n",
    "    def tokenize(self, sentence):\n",
    "        sentence = sentence.lower()\n",
    "        return self.tokenizer(sentence)\n",
    "\n",
    "    \n",
    "    def add_word(self, word):\n",
    "        if word not in self.char2idx:\n",
    "            self.char2idx[word] = self.vocab_count\n",
    "            self.idx2char.append(word)\n",
    "            self.vocab_count +=1 \n",
    "    \n",
    "    def build_vocab(self, vocabList):\n",
    "        for sentenceList in vocabList:\n",
    "            sentenceTokens = self.tokenize(sentenceList)\n",
    "            for token in sentenceTokens:\n",
    "                self.add_word(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, datapath):\n",
    "        \n",
    "        \"\"\"\n",
    "        Source: English\n",
    "        Target: Spanish\n",
    "        \"\"\"\n",
    "        \n",
    "        self.dataframe = pd.read_csv(datapath)\n",
    "        self.english = self.dataframe['eng']\n",
    "        self.spanish = self.dataframe['spa']\n",
    "        \n",
    "        self.englishVocab = Vocab(self.english.to_list(), language=\"english\")\n",
    "        self.spanishVocab = Vocab(self.spanish.to_list(), language=\"spanish\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        eng = self.english[idx]\n",
    "        spa = self.spanish[idx]\n",
    "        \n",
    "        eng = self.englishVocab.tokenize(eng)\n",
    "        spa = self.spanishVocab.tokenize(spa) \n",
    "        #spa.reverse() ##Reversing word distance as stated in paper\n",
    "        \n",
    "        eng = [self.englishVocab.sos] + eng + [self.englishVocab.eos]\n",
    "        spa = [self.spanishVocab.sos] + spa + [self.spanishVocab.eos]\n",
    "        \n",
    "        eng = torch.LongTensor([self.englishVocab.char2idx[token] for token in eng])\n",
    "        \n",
    "        spa = torch.LongTensor([self.spanishVocab.char2idx[token] for token in spa])\n",
    "                \n",
    "        return  eng, spa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.86 s, sys: 267 ms, total: 8.12 s\n",
      "Wall time: 8.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset = TranslationDataset('./eng-spa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(data):\n",
    "    eng = []\n",
    "    spa = []\n",
    "    \n",
    "    for dat in data:\n",
    "        eng.append(dat[0])\n",
    "        spa.append(dat[1])\n",
    "        \n",
    "    eng = pad_sequence(eng, padding_value = PAD_IDX, batch_first=True)\n",
    "    spa = pad_sequence(spa, padding_value = PAD_IDX, batch_first=True)\n",
    "    \n",
    "    return eng, spa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, num_workers=18, batch_size=BATCH_SIZE, pin_memory=True, collate_fn=collate, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab, hidden_dim, encoder_embedding_dim, num_layers):\n",
    "        \n",
    "        super(Encoder, self).__init__() \n",
    "        \n",
    "        self.vocab_size = vocab.vocab_count\n",
    "        self.embedding_dim = encoder_embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.emb = nn.Embedding(num_embeddings=self.vocab_size, embedding_dim=self.embedding_dim)\n",
    "        \n",
    "        self.GRU = nn.GRU(self.embedding_dim, hidden_dim, num_layers=self.num_layers, dropout=0.5, batch_first=True)\n",
    "        \n",
    "        \n",
    "    def forward(self, sentence, encoder_hidden_state):\n",
    "        \n",
    "        embedded = self.emb(sentence)\n",
    "        \n",
    "        out, hidden_state = self.GRU(embedded, encoder_hidden_state)\n",
    "        \n",
    "        return out, hidden_state\n",
    "    \n",
    "    def initHidden(self, BATCH_SIZE):\n",
    "        return torch.zeros(self.num_layers, BATCH_SIZE ,self.hidden_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab, hidden_dim, embedding_dim, num_layers):\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab.vocab_count\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        self.GRU = nn.GRU(self.embedding_dim, hidden_dim, num_layers=self.num_layers, batch_first=True, dropout=0.5)\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.vocab_size, embedding_dim=self.embedding_dim)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, self.vocab_size)\n",
    "        \n",
    "    def forward(self, y, hidden_state):\n",
    "        \n",
    "        y = self.embedding(y)\n",
    "        \n",
    "        lstm_out, decoder_hidden_state = self.GRU(y, hidden_state)\n",
    "        \n",
    "        logits = self.fc(lstm_out)\n",
    "                \n",
    "        return logits, decoder_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, hidden_dim, embedding_dim, hidden_layers, english_vocab, spanish_vocab):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        \n",
    "        self.eng_vocab = english_vocab\n",
    "        self.spa_vocab = spanish_vocab\n",
    "        \n",
    "        self.encoder = Encoder(self.eng_vocab, hidden_dim, embedding_dim, hidden_layers)\n",
    "        self.decoder = Decoder(self.spa_vocab, hidden_dim, embedding_dim, hidden_layers)\n",
    "        \n",
    "    \n",
    "    def forward(self, x, y, teacher_forcing = 0):\n",
    "        self.encoder.train()\n",
    "        self.decoder.train()\n",
    "        \n",
    "        current_batch_size, max_seq_len = y.shape\n",
    "\n",
    "        encoder_hidden = self.encoder.initHidden(current_batch_size).to(device)\n",
    "        encoder_output, encoder_hidden = self.encoder.forward(x, encoder_hidden)\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        del encoder_hidden\n",
    "        \n",
    "        outputs = torch.zeros(size=(max_seq_len - 1, current_batch_size, self.decoder.vocab_size)).to(device)\n",
    "\n",
    "        prev_word = torch.zeros_like(y[:, 0])\n",
    "\n",
    "        for i in range(max_seq_len - 1):\n",
    "\n",
    "            if random.random() < teacher_forcing: #Teacher forcing\n",
    "                logits, decoder_hidden = self.decoder.forward(y[:, i].unsqueeze(1), decoder_hidden)\n",
    "            else:\n",
    "                logits, decoder_hidden = self.decoder.forward(prev_word.unsqueeze(1), decoder_hidden)  #Teacher forcing: Get random then pass i from y if > proba else pass previous scores: TODO\n",
    "\n",
    "            prev_word = logits.argmax(dim=-1).squeeze(1)\n",
    "\n",
    "            outputs[i] = logits.squeeze(1)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_optimizers(model, lr=1e-5, weight_decay=0):\n",
    "    return torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(hidden_dim=1024, embedding_dim=1024, hidden_layers=16, english_vocab=dataset.englishVocab, spanish_vocab=dataset.spanishVocab).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = configure_optimizers(model)\n",
    "\n",
    "lr = 5.0 # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, x, y, teacher_forcing = 0.5, clip=5):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    with autocast():\n",
    "        outputs = model.forward(x, y, teacher_forcing)\n",
    "        loss = criterion(outputs.permute(1, 2, 0), y[:, 1:])\n",
    "        \n",
    "    loss.backward()\n",
    "    \n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "    optimizer.step()\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Started: Thu Dec 17 07:43:23 2020\n",
      "---------------------------------------------------------\n",
      "Epoch: 1, Batch: 0,   Batch Loss: 10.1989 \n",
      "Epoch: 1, Batch: 100,   Batch Loss: 15.1768 \n",
      "Epoch: 1, Batch: 200,   Batch Loss: 34.8389 \n",
      "Epoch: 1, Batch: 300,   Batch Loss: 24.1492 \n",
      "Epoch: 1, Batch: 400,   Batch Loss: 19.7926 \n",
      "Epoch: 1, Batch: 500,   Batch Loss: 27.5946 \n",
      "Epoch: 1, Batch: 600,   Batch Loss: 23.1040 \n",
      "Epoch: 1, Batch: 700,   Batch Loss: 20.4024 \n",
      "Epoch: 1, Batch: 800,   Batch Loss: 34.9231 \n",
      "Epoch: 1, Batch: 900,   Batch Loss: 19.4727 \n",
      "\n",
      "\n",
      "Epoch: 1, Mean Epoch Loss: 24.3179\n",
      "---------------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch: 2, Started: Thu Dec 17 07:49:23 2020\n",
      "---------------------------------------------------------\n",
      "Epoch: 2, Batch: 0,   Batch Loss: 20.7104 \n",
      "Epoch: 2, Batch: 100,   Batch Loss: 17.1363 \n",
      "Epoch: 2, Batch: 200,   Batch Loss: 13.0389 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-5c612b30eea5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-ef33f7acfe77>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, optimizer, x, y, teacher_forcing, clip)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-05c254c3a88e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y, teacher_forcing)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#Teacher forcing: Get random then pass i from y if > proba else pass previous scores: TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mprev_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-ae1e005d487c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, y, hidden_state)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    740\u001b[0m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    741\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    print(\"Epoch: {}, Started: {}\".format(epoch+1, time.ctime()))\n",
    "    print(\"---------------------------------------------------------\")\n",
    "\n",
    "    \n",
    "    for batch_IDX, batch in enumerate(dataloader):    \n",
    "        \n",
    "        x, y = batch\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        batch_loss = train_step(model, optimizer, x, y)\n",
    "\n",
    "        epoch_loss += batch_loss\n",
    "\n",
    "        if batch_IDX % print_every == 0:\n",
    "            print(\"Epoch: {}, Batch: {},   Batch Loss: {:.4f} \".format(epoch+1, batch_IDX, batch_loss))\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"Epoch: {}, Mean Epoch Loss: {:.4f}\".format(epoch+1, epoch_loss / len(dataloader)))\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    print(\"\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_translation(encoder, decoder, sentence, max_len=50):\n",
    "    \n",
    "    sentence = dataset.englishVocab.tokenize(sentence)\n",
    "    sentence = [[dataset.englishVocab.char2idx.get(token, dataset.englishVocab.char2idx[oov]) for token in sentence]]\n",
    "    sentence = torch.LongTensor(sentence).to(device)\n",
    "    \n",
    "    encoder_hidden = encoder.initHidden(1).to(device)\n",
    "    _, encoder_hidden = encoder(sentence, encoder_hidden)\n",
    "    \n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    word = [[dataset.spanishVocab.char2idx[sos]]]\n",
    "    word = torch.LongTensor(word).to(device)\n",
    "    \n",
    "    translation = []\n",
    "    \n",
    "    i = 0\n",
    "    word_str = None\n",
    "    while i < max_len and word_str != eos:\n",
    "        \n",
    "        decoder_out, decoder_hidden = decoder(word, decoder_hidden)\n",
    "        \n",
    "        word = decoder_out.argmax(dim=-1)\n",
    "        print(word)\n",
    "        word_str = dataset.spanishVocab.idx2char[decoder_out.argmax().item()]\n",
    "        translation.append(word_str)\n",
    "        i += 1\n",
    "    \n",
    "    return translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[229]], device='cuda:0')\n",
      "tensor([[128]], device='cuda:0')\n",
      "tensor([[121]], device='cuda:0')\n",
      "tensor([[51]], device='cuda:0')\n",
      "tensor([[118]], device='cuda:0')\n",
      "tensor([[1]], device='cuda:0')\n",
      "el quÃ© la , en |<eos>|\n"
     ]
    }
   ],
   "source": [
    "with torch.autograd.no_grad():\n",
    "    print(\" \".join(generate_translation(model.encoder, model.decoder, \"do you have something to say?\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
